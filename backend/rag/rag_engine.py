"""
RAG Engine - —Å–∏—Å—Ç–µ–º–∞ –ø–æ–∏—Å–∫–∞ –ø–æ –≤–µ–∫—Ç–æ—Ä–Ω—ã–º –±–∞–∑–∞–º –∑–Ω–∞–Ω–∏–π
–ü–æ–¥–¥–µ—Ä–∂–∫–∞: Voyage AI (embeddings) + DeepSeek (–≥–µ–Ω–µ—Ä–∞—Ü–∏—è)
"""
from typing import List, Dict, Optional
import logging
import httpx
import time

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class VoyageEmbeddings:
    """–ö–ª–∏–µ–Ω—Ç –¥–ª—è Voyage AI Embeddings"""
    
    def __init__(
        self, 
        api_key: str, 
        model: str = "voyage-multilingual-2"
    ):
        self.api_key = api_key
        self.model = model
        self.base_url = "https://api.voyageai.com/v1"  # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: —É–±—Ä–∞–Ω—ã –ø—Ä–æ–±–µ–ª—ã –≤ –∫–æ–Ω—Ü–µ!
    
    def embed(self, text: str, input_type: str = "document") -> List[float]:
        """–ü–æ–ª—É—á–∏—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞"""
        return self.embed_batch([text], input_type)[0]
    
    def embed_query(self, text: str) -> List[float]:
        """–≠–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞"""
        return self.embed(text, input_type="query")
    
    def embed_batch(self, texts: List[str], input_type: str = "document") -> List[List[float]]:
        """–ü–æ–ª—É—á–∏—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è —Å–ø–∏—Å–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤"""
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": self.model,
            "input": texts,
            "input_type": input_type
        }
        
        with httpx.Client(timeout=60.0) as client:
            response = client.post(
                f"{self.base_url}/embeddings",
                headers=headers,
                json=payload
            )
            response.raise_for_status()
            data = response.json()
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∏–Ω–¥–µ–∫—Å—É
        sorted_data = sorted(data["data"], key=lambda x: x["index"])
        return [item["embedding"] for item in sorted_data]


class RAGEngine:
    """–°–∏—Å—Ç–µ–º–∞ RAG –¥–ª—è –ø–æ–∏—Å–∫–∞ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ñ–∏–ª—å—Ç—Ä–æ–≤"""
    
    def __init__(
        self,
        api_key: str,
        pinecone_api_key: str,
        index_name: str,
        agent_type: str = None,  # 'ntd' –∏–ª–∏ 'docs'
        embedding_model: str = "voyage-multilingual-2",
        embedding_dimension: int = 1024,
        top_k: int = 3,
        base_url: str = None,
        ai_provider: str = "deepseek",
        voyage_api_key: str = None,
        embedding_provider: str = "voyage"
    ):
        """
        Args:
            api_key: –∫–ª—é—á API –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (DeepSeek)
            pinecone_api_key: –∫–ª—é—á Pinecone API
            index_name: –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ –≤ Pinecone
            agent_type: —Ç–∏–ø –∞–≥–µ–Ω—Ç–∞ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ ('ntd' –∏–ª–∏ 'docs')
            embedding_model: –º–æ–¥–µ–ª—å –¥–ª—è embeddings
            embedding_dimension: —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä–æ–≤ (1024 –¥–ª—è Voyage)
            top_k: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞
            base_url: –±–∞–∑–æ–≤—ã–π URL API (–¥–ª—è DeepSeek)
            ai_provider: –ø—Ä–æ–≤–∞–π–¥–µ—Ä AI –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (deepseek)
            voyage_api_key: –∫–ª—é—á Voyage AI –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
            embedding_provider: –ø—Ä–æ–≤–∞–π–¥–µ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ (voyage –∏–ª–∏ openai)
        """
        self.api_key = api_key
        self.pinecone_api_key = pinecone_api_key
        self.embedding_model = embedding_model
        self.embedding_dimension = embedding_dimension
        self.top_k = top_k
        self.index_name = index_name
        self.base_url = base_url
        self.ai_provider = ai_provider
        self.agent_type = agent_type
        self.embedding_provider = embedding_provider
        self.voyage_api_key = voyage_api_key
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Voyage –∫–ª–∏–µ–Ω—Ç–∞
        if embedding_provider == "voyage" and voyage_api_key:
            self.voyage_client = VoyageEmbeddings(
                api_key=voyage_api_key,
                model=embedding_model
            )
            logger.info(f"‚úÖ Voyage AI –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω: {embedding_model}")
        else:
            self.voyage_client = None
        
        # –ë—É–¥–µ—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –ø—Ä–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–∏
        self.index = None
    
    def create_embedding(self, text: str, is_query: bool = False) -> List[float]:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ embedding –¥–ª—è —Ç–µ–∫—Å—Ç–∞
        
        Args:
            text: –≤—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç
            is_query: True –µ—Å–ª–∏ —ç—Ç–æ –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            
        Returns:
            –≤–µ–∫—Ç–æ—Ä embedding
        """
        # Voyage AI
        if self.embedding_provider == "voyage" and self.voyage_client:
            try:
                if is_query:
                    return self.voyage_client.embed_query(text)
                else:
                    return self.voyage_client.embed(text)
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ Voyage AI: {e}")
                raise
        
        # Fallback –Ω–∞ OpenAI
        import openai
        
        if self.base_url:
            client = openai.OpenAI(api_key=self.api_key, base_url=self.base_url)
        else:
            client = openai.OpenAI(api_key=self.api_key)
        
        try:
            response = client.embeddings.create(input=text, model=self.embedding_model)
            return response.data[0].embedding
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ embedding: {e}")
            raise
    
    def search(self, query: str, top_k: Optional[int] = None) -> List[Dict]:
        """
        –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –ø–æ —Ç–∏–ø—É –∞–≥–µ–Ω—Ç–∞
        
        Args:
            query: –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            top_k: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            
        Returns:
            —Å–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        """
        if not self.index:
            logger.error("–ò–Ω–¥–µ–∫—Å –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            return []
        
        if top_k is None:
            top_k = self.top_k
        
        try:
            # –°–æ–∑–¥–∞–µ–º embedding –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ (is_query=True –¥–ª—è Voyage)
            query_embedding = self.create_embedding(query, is_query=True)
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Ñ–∏–ª—å—Ç—Ä –ø–æ —Ç–∏–ø—É –∞–≥–µ–Ω—Ç–∞
            search_filter = None
            if self.agent_type:
                search_filter = {"agent_type": self.agent_type}
                logger.info(f"–ü–æ–∏—Å–∫ —Å —Ñ–∏–ª—å—Ç—Ä–æ–º: {search_filter}")
            
            # –ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ –≤–µ–∫—Ç–æ—Ä—ã —Å —Ñ–∏–ª—å—Ç—Ä–æ–º
            results = self.index.query(
                vector=query_embedding,
                top_k=top_k,
                include_metadata=True,
                filter=search_filter  # –§–∏–ª—å—Ç—Ä –ø–æ —Ç–∏–ø—É –∞–≥–µ–Ω—Ç–∞!
            )
            
            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            documents = []
            for match in results['matches']:
                documents.append({
                    'id': match['id'],
                    'score': match['score'],
                    'text': match['metadata'].get('text', ''),
                    'metadata': {k: v for k, v in match['metadata'].items() if k != 'text'}
                })
            
            return documents
        
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ: {e}")
            return []
    
    def delete_documents_by_filename(self, filename: str) -> bool:
        """
        –£–¥–∞–ª–µ–Ω–∏–µ –≤—Å–µ—Ö —á–∞–Ω–∫–æ–≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –ø–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
        
        Args:
            filename: –∏–º—è —Ñ–∞–π–ª–∞ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
            
        Returns:
            —É—Å–ø–µ—à–Ω–æ—Å—Ç—å —É–¥–∞–ª–µ–Ω–∏—è
        """
        if not self.index:
            logger.error("–ò–Ω–¥–µ–∫—Å –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            return False
        
        try:
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Ñ–∏–ª—å—Ç—Ä
            delete_filter = {"filename": filename}
            if self.agent_type:
                delete_filter["agent_type"] = self.agent_type
            
            # –£–¥–∞–ª—è–µ–º –ø–æ —Ñ–∏–ª—å—Ç—Ä—É
            self.index.delete(filter=delete_filter)
            
            logger.info(f"‚úÖ –£–¥–∞–ª–µ–Ω—ã –≤—Å–µ —á–∞–Ω–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {filename}")
            return True
        
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏: {e}")
            return False
    
    def list_documents(self) -> List[str]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∞–≥–µ–Ω—Ç–∞
        
        Returns:
            —Å–ø–∏—Å–æ–∫ –∏–º—ë–Ω —Ñ–∞–π–ª–æ–≤
        """
        if not self.index:
            logger.error("–ò–Ω–¥–µ–∫—Å –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            return []
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–Ω–¥–µ–∫—Å–∞
            stats = self.index.describe_index_stats()
            
            # –í Pinecone –Ω–µ—Ç –ø—Ä—è–º–æ–≥–æ —Å–ø–æ—Å–æ–±–∞ –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ –≤–µ–∫—Ç–æ—Ä–æ–≤
            namespaces = stats.get('namespaces', {})
            
            logger.info(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–Ω–¥–µ–∫—Å–∞: {stats}")
            
            return []  # Pinecone –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –Ω–∞–ø—Ä—è–º—É—é
        
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞: {e}")
            return []
    
    def init_index(self, pinecone_api_key: str = None):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏–Ω–¥–µ–∫—Å–∞ Pinecone"""
        from pinecone import Pinecone
        
        api_key = pinecone_api_key or self.pinecone_api_key
        pc = Pinecone(api_key=api_key)
        self.index = pc.Index(self.index_name)
        logger.info(f"‚úÖ Pinecone –∏–Ω–¥–µ–∫—Å –ø–æ–¥–∫–ª—é—á–µ–Ω: {self.index_name}")
    
    def add_documents(self, documents: List[Dict], batch_size: int = 100):
        """
        –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –±–∞—Ç—á–∏–Ω–≥ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è –æ–±—Ö–æ–¥–∞ rate limit
        
        Args:
            documents: —Å–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ [{id, text, metadata}, ...]
            batch_size: —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏
        """
        from pinecone import Pinecone
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Pinecone –µ—Å–ª–∏ –Ω–µ –±—ã–ª–æ
        if not self.index:
            pc = Pinecone(api_key=self.pinecone_api_key)
            self.index = pc.Index(self.index_name)
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Ç–µ–∫—Å—Ç—ã –¥–ª—è –±–∞—Ç—á-—ç–º–±–µ–¥–¥–∏–Ω–≥–∞
        texts = [doc['text'] for doc in documents]
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –û–î–ù–ò–ú –∑–∞–ø—Ä–æ—Å–æ–º (–±–∞—Ç—á)
        logger.info(f"üìä –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è {len(texts)} —á–∞–Ω–∫–æ–≤ –æ–¥–Ω–∏–º –∑–∞–ø—Ä–æ—Å–æ–º...")
        
        # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –±—ã–ª–æ self.voyage_embeddings ‚Üí —Å—Ç–∞–ª–æ self.voyage_client
        if self.embedding_provider == "voyage" and self.voyage_client:
            embeddings = self.voyage_client.embed_batch(texts, input_type="document")
        else:
            # Fallback - –ø–æ –æ–¥–Ω–æ–º—É (–¥–ª—è OpenAI)
            embeddings = []
            for text in texts:
                emb = self.create_embedding(text, is_query=False)
                embeddings.append(emb)
                time.sleep(0.5)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –≤–µ–∫—Ç–æ—Ä—ã
        vectors = []
        for i, doc in enumerate(documents):
            vectors.append({
                'id': doc['id'],
                'values': embeddings[i],
                'metadata': {
                    'text': doc['text'][:8000],  # –õ–∏–º–∏—Ç Pinecone
                    **doc.get('metadata', {})
                }
            })
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ Pinecone –±–∞—Ç—á–∞–º–∏
        for i in range(0, len(vectors), batch_size):
            batch = vectors[i:i+batch_size]
            self.index.upsert(vectors=batch)
            logger.info(f"üì§ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(batch)} –≤–µ–∫—Ç–æ—Ä–æ–≤")
        
        logger.info(f"‚úÖ –í—Å–µ–≥–æ –¥–æ–±–∞–≤–ª–µ–Ω–æ {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")

    def generate_answer(
        self,
        query: str,
        context_documents: List[Dict],
        model: str = "deepseek-chat",
        system_prompt: Optional[str] = None
    ) -> str:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        """
        import openai
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–ª–∏–µ–Ω—Ç–∞
        if self.base_url:
            client = openai.OpenAI(
                api_key=self.api_key,
                base_url=self.base_url
            )
        else:
            client = openai.OpenAI(api_key=self.api_key)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        context = "\n\n".join([
            f"–î–æ–∫—É–º–µ–Ω—Ç {i+1}:\n{doc['text']}"
            for i, doc in enumerate(context_documents)
        ])
        
        if system_prompt is None:
            system_prompt = """–¢—ã - AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö.
–û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ —Å—É—â–µ—Å—Ç–≤—É.
–ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ—Ç –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö - —Ç–∞–∫ –∏ —Å–∫–∞–∂–∏."""
        
        user_prompt = f"""–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:
{context}

–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {query}

–û—Ç–≤–µ—Ç:"""
        
        try:
            response = client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.3,
                max_tokens=1000
            )
            
            return response.choices[0].message.content
        
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
            return "–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞."


if __name__ == "__main__":
    print("RAG Engine –º–æ–¥—É–ª—å –≥–æ—Ç–æ–≤!")
